{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "867156a0-f1bd-4bde-8476-aef11fd8b3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from pytrends.request import TrendReq\n",
    "from statsmodels.tsa.stattools import kpss, adfuller\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from statsmodels.graphics.tsaplots import *\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "from xgboost import plot_importance, plot_tree\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fb886a61-9d94-4084-8841-d1dd93ca5825",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>REF_DATE</th>\n",
       "      <th>GEO</th>\n",
       "      <th>DGUID</th>\n",
       "      <th>Sales</th>\n",
       "      <th>UOM</th>\n",
       "      <th>UOM_ID</th>\n",
       "      <th>SCALAR_FACTOR</th>\n",
       "      <th>SCALAR_ID</th>\n",
       "      <th>VECTOR</th>\n",
       "      <th>COORDINATE</th>\n",
       "      <th>VALUE</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>SYMBOL</th>\n",
       "      <th>TERMINATED</th>\n",
       "      <th>DECIMALS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01</td>\n",
       "      <td>Canada</td>\n",
       "      <td>2016A000011124</td>\n",
       "      <td>Retail trade, unadjusted\\n [44-453]</td>\n",
       "      <td>Dollars</td>\n",
       "      <td>81</td>\n",
       "      <td>thousands</td>\n",
       "      <td>3</td>\n",
       "      <td>v108795018</td>\n",
       "      <td>1.1</td>\n",
       "      <td>37415147</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01</td>\n",
       "      <td>Canada</td>\n",
       "      <td>2016A000011124</td>\n",
       "      <td>Electronic shopping and mail-order houses, una...</td>\n",
       "      <td>Dollars</td>\n",
       "      <td>81</td>\n",
       "      <td>thousands</td>\n",
       "      <td>3</td>\n",
       "      <td>v108795019</td>\n",
       "      <td>1.2</td>\n",
       "      <td>679612</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  REF_DATE     GEO           DGUID  \\\n",
       "0  2016-01  Canada  2016A000011124   \n",
       "1  2016-01  Canada  2016A000011124   \n",
       "\n",
       "                                               Sales      UOM  UOM_ID  \\\n",
       "0                Retail trade, unadjusted\\n [44-453]  Dollars      81   \n",
       "1  Electronic shopping and mail-order houses, una...  Dollars      81   \n",
       "\n",
       "  SCALAR_FACTOR  SCALAR_ID      VECTOR  COORDINATE     VALUE STATUS  SYMBOL  \\\n",
       "0     thousands          3  v108795018         1.1  37415147      A     NaN   \n",
       "1     thousands          3  v108795019         1.2    679612      B     NaN   \n",
       "\n",
       "   TERMINATED  DECIMALS  \n",
       "0         NaN         0  \n",
       "1         NaN         0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../../data/retailEcommercesales/retailEcommerceSales.csv',sep=',')\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d29682ed-7353-4536-8e1f-b47dd7cd9b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data filter\n",
    "retailEcommercesales = data[~data[\"Sales\"].str.contains('unadjusted')]\n",
    "retailEcommercesales = retailEcommercesales.filter(['REF_DATE','VALUE'])\n",
    "\n",
    "# rename columns\n",
    "retailEcommercesales = retailEcommercesales.rename(columns = {'REF_DATE': 'Date', 'VALUE': 'Ecommerce_sales'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fd6a33cc-0a0f-4f63-a61e-6c0b471319d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ecommerce_sales</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01</th>\n",
       "      <td>977198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-02</th>\n",
       "      <td>1006610</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Ecommerce_sales\n",
       "Date                    \n",
       "2016-01           977198\n",
       "2016-02          1006610"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retailEcommercesales_ts = retailEcommercesales.set_index('Date')\n",
    "retailEcommercesales_ts.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3eccedf1-dff3-43a3-9f7e-b8858e321f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "retailEcommercesales_ts['Growth_rate'] = retailEcommercesales_ts.pct_change()\n",
    "retailEcommercesales_ts = retailEcommercesales_ts.dropna() # removing NA\n",
    "retailEcommercesales_ts.index = pd.to_datetime(retailEcommercesales_ts[['Growth_rate']].index)\n",
    "#plt.plot(retailEcommercesales_ts['Growth_rate'])\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2d73d63a-9705-489b-ad27-5a6081920430",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_df(y, title=\"\", xlabel='Date', ylabel='Value', dpi=100, width = 16, height = 5):\n",
    "    plt.figure(figsize=(width,height), dpi=dpi)\n",
    "    plt.plot(y)\n",
    "    plt.gca().set(title=title, xlabel=xlabel, ylabel=ylabel)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "397352e9-b12e-49b1-a6a5-459245d0b3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecommerce_keyword_ts = pd.read_csv('EcommerceKeywordTimeSeries.csv')\n",
    "ecommerce_keyword_ts.rename(columns = {'date':'Date'}, inplace = True)\n",
    "ecommerce_keyword_ts = ecommerce_keyword_ts.set_index(['Date'])\n",
    "ecommerce_keyword_ts.index = pd.to_datetime(ecommerce_keyword_ts.index)\n",
    "ecommerce_keyword_ts = ecommerce_keyword_ts.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a0a167da-f2c8-400f-973c-cdb27fb201bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Uber</th>\n",
       "      <th>DoorDash</th>\n",
       "      <th>SkipTheDishes</th>\n",
       "      <th>Walmart</th>\n",
       "      <th>Costco</th>\n",
       "      <th>Real Canadian Superstore</th>\n",
       "      <th>alibaba</th>\n",
       "      <th>newegg canada</th>\n",
       "      <th>ebay</th>\n",
       "      <th>kijiji</th>\n",
       "      <th>...</th>\n",
       "      <th>Sportchek</th>\n",
       "      <th>square online</th>\n",
       "      <th>PayPal</th>\n",
       "      <th>Western Union</th>\n",
       "      <th>TD Canada Trust</th>\n",
       "      <th>Scotiabank</th>\n",
       "      <th>Royal Bank of Canada</th>\n",
       "      <th>Google Pay</th>\n",
       "      <th>Apple Pay</th>\n",
       "      <th>Mastercard</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2004-01-01</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-02-01</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>44</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Uber  DoorDash  SkipTheDishes  Walmart  Costco  \\\n",
       "Date                                                         \n",
       "2004-01-01     0         0              0        0       0   \n",
       "2004-02-01     0         0              0        0       0   \n",
       "\n",
       "            Real Canadian Superstore  alibaba  newegg canada  ebay  kijiji  \\\n",
       "Date                                                                         \n",
       "2004-01-01                         0        0              0    60       0   \n",
       "2004-02-01                         0        0              0    12       0   \n",
       "\n",
       "            ...  Sportchek  square online  PayPal  Western Union  \\\n",
       "Date        ...                                                    \n",
       "2004-01-01  ...          0              0      54             40   \n",
       "2004-02-01  ...          0              0      48             44   \n",
       "\n",
       "            TD Canada Trust  Scotiabank  Royal Bank of Canada  Google Pay  \\\n",
       "Date                                                                        \n",
       "2004-01-01                0           0                    80           0   \n",
       "2004-02-01               46           0                     0           0   \n",
       "\n",
       "            Apple Pay  Mastercard  \n",
       "Date                               \n",
       "2004-01-01          0           0  \n",
       "2004-02-01          0           0  \n",
       "\n",
       "[2 rows x 30 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ecommerce_keyword_ts.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "39cb389a-124a-4565-89b3-5d3a55aa2557",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_long_term_trend(dataframe, freq='M'):\n",
    "    \"\"\"extract the monthly trend from the series\"\"\"\n",
    "    dataframe = np.log(dataframe)\n",
    "    long_term_trend_data = dataframe.copy()\n",
    "    if freq == 'Q':\n",
    "        lamb = 1600\n",
    "    elif freq == 'M':\n",
    "        lamb = 1600*3**4\n",
    "    for column_name in dataframe.columns:\n",
    "        cycle, trend = sm.tsa.filters.hpfilter(dataframe[column_name], lamb)\n",
    "        long_term_trend_data[column_name] = trend\n",
    "    return long_term_trend_data\n",
    "\n",
    "\n",
    "def remove_downward_trend_bias(dataframe, gdp_categoryts_df, freq = 'M'):\n",
    "    \"\"\"pass dataframe to remove bias and downward trend\"\"\"\n",
    "    trend_data = get_long_term_trend(gdp_categoryts_df, freq)\n",
    "    log_category = np.log(dataframe)\n",
    "    log_category.replace([np.inf, -np.inf], 0, inplace=True)\n",
    "    avg_logcategory = log_category.mean()\n",
    "    pca = PCA(n_components=1)\n",
    "    pca.fit(trend_data)\n",
    "    component = pd.DataFrame(pca.fit_transform(trend_data))\n",
    "\n",
    "    # rescale component\n",
    "    # transformation source link: https://stats.stackexchange.com/questions/46429/transform-data-to-desired-mean-and-standard-deviation\n",
    "    rescaled_component = avg_logcategory.mean() + (component - component.mean())*(avg_logcategory.std()/component.std())\n",
    "    \n",
    "    # remove long term bias\n",
    "    transformed_data = log_category - rescaled_component.values\n",
    "    transformed_data.index = pd.to_datetime(transformed_data.index)\n",
    "\n",
    "    return transformed_data\n",
    "\n",
    "\n",
    "def make_predictors_df(*arg):\n",
    "    \"\"\"joins the predictors dataframes\"\"\"\n",
    "    if len(arg) > 1:\n",
    "        for i in range(0, len(arg)-1):\n",
    "            if i == 0:\n",
    "                arg[i].index = pd.to_datetime(arg[i].index)\n",
    "                arg[i+1].index = pd.to_datetime(arg[i+1].index)\n",
    "                predictors_df = pd.merge(arg[i], arg[i+1], left_index=True, right_index=True)\n",
    "            else:\n",
    "                predictors_df = pd.merge(predictors_df, arg[i+1], left_index=True, right_index=True)\n",
    "    else:\n",
    "        arg[0].index = pd.to_datetime(arg[0].index)\n",
    "        return arg[0]\n",
    "    return predictors_df\n",
    "\n",
    "def normalize(dataframe):\n",
    "    \"\"\"function to normalize dataframe\"\"\"\n",
    "    data = dataframe.copy()\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(dataframe)\n",
    "    scaled_df = pd.DataFrame(scaler.transform(dataframe))\n",
    "    scaled_df.index = data.index\n",
    "    scaled_df.columns = data.columns\n",
    "    return scaled_df\n",
    "\n",
    "# difference\n",
    "def detrend(dataframe):\n",
    "    \"\"\"function to detrend time series\"\"\"\n",
    "    return dataframe.diff().dropna()\n",
    "\n",
    "# seasonality\n",
    "def remove_seasonality(dataframe):\n",
    "    \"\"\"function for differencing of time series\"\"\"\n",
    "    data = dataframe.copy()\n",
    "    # monthly mean\n",
    "    mean_data = dataframe.groupby(dataframe.index.month).mean()\n",
    "    \n",
    "    for i, d in enumerate(data.index):\n",
    "        data.iloc[i,:] = mean_data.loc[d.month]\n",
    "    removed_seaonality_data = dataframe - data\n",
    "    return removed_seaonality_data\n",
    "\n",
    "# cyclicity \n",
    "def remove_volatility(dataframe):\n",
    "    \"\"\"function for removing volatility of time series\"\"\"\n",
    "    data = dataframe.copy()\n",
    "    # monthly mean\n",
    "    std_data = dataframe.groupby(dataframe.index.year).std()\n",
    "    for i, d in enumerate(data.index):\n",
    "        data.iloc[i,:] = std_data.loc[d.year]\n",
    "    removed_vol_data = dataframe - data\n",
    "    return removed_vol_data\n",
    "\n",
    "def adf_test(timeseries):\n",
    "    #print(\"Results of Dickey-Fuller Test:\")\n",
    "    dftest = adfuller(timeseries, autolag=\"AIC\")\n",
    "    dfoutput = pd.Series(\n",
    "        dftest[0:4],\n",
    "        index=[\n",
    "            \"Test Statistic\",\n",
    "            \"p-value\",\n",
    "            \"#Lags Used\",\n",
    "            \"Number of Observations Used\",\n",
    "        ],\n",
    "    )\n",
    "    for key, value in dftest[4].items():\n",
    "        dfoutput[\"Critical Value (%s)\" % key] = value\n",
    "    #print(dfoutput)\n",
    "    if dftest[1] < 0.05:\n",
    "        return f\"Series is stationary\"\n",
    "    else:\n",
    "        return f\"Series is not stationary\"\n",
    "\n",
    "\n",
    "def kpss_test(timeseries):\n",
    "    #print(\"Results of KPSS Test:\")\n",
    "    kpsstest = kpss(timeseries, regression=\"c\", nlags=\"auto\")\n",
    "    kpss_output = pd.Series(\n",
    "        kpsstest[0:3], index=[\"Test Statistic\", \"p-value\", \"Lags Used\"]\n",
    "    )\n",
    "    for key, value in kpsstest[3].items():\n",
    "        kpss_output[\"Critical Value (%s)\" % key] = value\n",
    "    #print(kpss_output)\n",
    "    if kpsstest[1] > 0.05:\n",
    "        return f\"Series is stationary\"\n",
    "    else:\n",
    "        return f\"Series is not stationary\"\n",
    "        \n",
    "def check_stationarity(dataframe):\n",
    "    for i in range(0,dataframe.shape[1]):\n",
    "        timeseries = dataframe.iloc[:,i]\n",
    "        adf_result = adf_test(timeseries)\n",
    "        kpss_result = kpss_test(timeseries)\n",
    "        if (adf_result == \"Series is stationary\") and (kpss_result == \"Series is stationary\"):\n",
    "            pass\n",
    "        elif (adf_result == \"Series is not stationary\") and (kpss_result == \"Series is not stationary\"):\n",
    "            print(f\"Series {dataframe.columns[i]} is not stationary\")\n",
    "        elif (adf_result == \"Series is stationary\") and (kpss_result == \"Series is not stationary\"):\n",
    "            print(f\"Series {dataframe.columns[i]} is not stationary, differencing can be used to make it stationary\")\n",
    "        elif (adf_result == \"Series is not stationary\") and (kpss_result == \"Series is stationary\"):\n",
    "            print(f\"Series {dataframe.columns[i]} is trend stationary, trend needs to be removed\")\n",
    "    print(\"All other series are stationary\")\n",
    "\n",
    "def ts_train_test_split(response, predictor, test_size):\n",
    "    \" splits the train and test set and also returns the extra test data of predictors\"\n",
    "    # train test split\n",
    "    joind_df = pd.merge(response, predictor, left_index=True, right_index=True)\n",
    "    train, test = train_test_split(joind_df, test_size=test_size, shuffle=False)\n",
    "    # extra test data\n",
    "    extra_test_data = predictor.loc[predictor.index > joind_df.index[len(joind_df.index)-1], :]\n",
    "    return train, test, extra_test_data\n",
    "\n",
    "def lag_plots(data):\n",
    "    \"\"\"plots acf and pacf plots\"\"\"\n",
    "    plot_acf(data)\n",
    "    plot_pacf(data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e44e6036-aed3-4ae0-aa62-c9e77ce47254",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2004-01-01', '2004-02-01', '2004-03-01', '2004-04-01',\n",
       "               '2004-05-01', '2004-06-01', '2004-07-01', '2004-08-01',\n",
       "               '2004-09-01', '2004-10-01',\n",
       "               ...\n",
       "               '2021-07-01', '2021-08-01', '2021-09-01', '2021-10-01',\n",
       "               '2021-11-01', '2021-12-01', '2022-01-01', '2022-02-01',\n",
       "               '2022-03-01', '2022-04-01'],\n",
       "              dtype='datetime64[ns]', name='date', length=220, freq=None)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdp_category_data = pd.read_csv(\"gdp_category_ts.csv\", index_col = 0)\n",
    "gdp_category_data.rename(index={'date': 'Date'}, inplace=True)\n",
    "gdp_category_data.index = pd.to_datetime(gdp_category_data.index) \n",
    "gdp_category_data.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dfcfbda6-1318-428c-bd50-12677a53b08b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ecommerce_sales</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-01</th>\n",
       "      <td>977198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-02-01</th>\n",
       "      <td>1006610</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Ecommerce_sales\n",
       "Date                       \n",
       "2016-01-01           977198\n",
       "2016-02-01          1006610"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retailEcommercesales = retailEcommercesales.set_index(['Date'])\n",
    "retailEcommercesales.index = pd.to_datetime(retailEcommercesales.index)\n",
    "retailEcommercesales.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "484d916f-dcb1-465b-95d2-b360c4991d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation check\n",
    "cols = list()\n",
    "data = pd.merge(retailEcommercesales, gdp_category_data, left_index=True, right_index=True)\n",
    "\n",
    "for i in range(0, data.iloc[:,2:].shape[1]):\n",
    "    corr, _ = pearsonr(data['Ecommerce_sales'], data.iloc[:, i+2])\n",
    "    if abs(corr) > 0.9:\n",
    "        cols.append(data.columns[i+2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4f415b1c-8eda-42a9-9090-945a686b160a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0d811ec7-eca3-4ef2-8b65-4d2e9ed225b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp_ecommerce_correlated_data = data[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "faa83353-e303-4def-8dc6-d6a4a54557e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>23</th>\n",
       "      <th>726</th>\n",
       "      <th>882</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-01</th>\n",
       "      <td>32</td>\n",
       "      <td>62</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-02-01</th>\n",
       "      <td>31</td>\n",
       "      <td>64</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-01</th>\n",
       "      <td>29</td>\n",
       "      <td>68</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-01</th>\n",
       "      <td>33</td>\n",
       "      <td>66</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-05-01</th>\n",
       "      <td>33</td>\n",
       "      <td>67</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-01</th>\n",
       "      <td>20</td>\n",
       "      <td>37</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-01</th>\n",
       "      <td>24</td>\n",
       "      <td>37</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-01</th>\n",
       "      <td>25</td>\n",
       "      <td>38</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01</th>\n",
       "      <td>21</td>\n",
       "      <td>40</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-01</th>\n",
       "      <td>22</td>\n",
       "      <td>40</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            23  726  882\n",
       "2016-01-01  32   62   58\n",
       "2016-02-01  31   64   59\n",
       "2016-03-01  29   68   57\n",
       "2016-04-01  33   66   62\n",
       "2016-05-01  33   67   61\n",
       "...         ..  ...  ...\n",
       "2021-10-01  20   37   72\n",
       "2021-11-01  24   37   73\n",
       "2021-12-01  25   38   72\n",
       "2022-01-01  21   40   77\n",
       "2022-02-01  22   40   77\n",
       "\n",
       "[74 rows x 3 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdp_ecommerce_correlated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a618af9-8355-4202-9c69-f8300c3f9620",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp_ecommerce_correlated_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e03bdb5-a958-4bb9-a9d3-68979e93ba65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c40dd9-0921-49fa-85e5-aded7b3827dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_category_merged = pd.merge(ecommerce_keyword_ts,gdp_ecommerce_correlated_data,left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a6f07d-605c-4c7c-b57f-558be9227697",
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_category_merged.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4aa0f2-b11a-4280-b82f-0b8f01082004",
   "metadata": {},
   "outputs": [],
   "source": [
    "#keyword_category_merged.drop('95', axis=1, inplace=True)\n",
    "normalized_merged_keyword = normalize(keyword_category_merged)\n",
    "detrend_merged_keyword = ((detrend(detrend(normalized_merged_keyword))))\n",
    "check_stationarity(detrend_merged_keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a79866e-5d4d-4bfb-89af-ae81d42114c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df, extra_df = ts_train_test_split(retailEcommercesales_ts[['Growth_rate']],detrend_merged_keyword, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22f198a-fe7d-4d8e-b620-49cda4736044",
   "metadata": {},
   "outputs": [],
   "source": [
    "lag_plots(retailEcommercesales_ts[['Growth_rate']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39aa1133-de9a-43b6-bdf9-a26084a609ad",
   "metadata": {},
   "source": [
    "#### Xgboost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efb1a37-9fdf-4f93-a6fe-fdbf0b3dd5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lag1_data(retailEcommercesales_ts, ecommerce_keyword_ts, dependent_var='Growth_rate'):\n",
    "    \"\"\" passed response dataframe and predictors' dataframe\"\"\"\n",
    "    lasso_key = detrend(normalize(ecommerce_keyword_ts))\n",
    "\n",
    "    # response\n",
    "    lasso_response = retailEcommercesales_ts[[dependent_var]].iloc[1:,:]\n",
    "\n",
    "    # extract lag1 data to add to predictors\n",
    "    lag1 = retailEcommercesales_ts[[dependent_var]].iloc[0:retailEcommercesales_ts.shape[0]-1,:]\n",
    "    lag1.index = lasso_response.index\n",
    "    lag1 = lag1.rename(columns={dependent_var: 'lag1'}) \n",
    "    lasso_predictors = make_predictors_df(lag1, lasso_key)\n",
    "    return lasso_predictors, lasso_response\n",
    "\n",
    "def xgboost_modelfit(train_xgboost, dependent_var='Growth_rate'):\n",
    "    \"\"\" fits xgboost model to the passed data\"\"\"\n",
    "    X_xgboost, Y_xgboost = train_xgboost.loc[:, ~train_xgboost.columns.isin([dependent_var])], train_xgboost[[dependent_var]]\n",
    "    xgboostmodel = XGBRegressor(objective ='reg:squarederror', n_estimators=1000)\n",
    "    xgboostmodel.fit(X_xgboost, Y_xgboost)\n",
    "    return xgboostmodel\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b976e013-646d-49a9-a577-b1e952bfe4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictor lag1\n",
    "xgboost_predictors, xgboost_response = get_lag1_data(retailEcommercesales_ts, detrend_merged_keyword)\n",
    "\n",
    "#model fitted on data split\n",
    "\n",
    "train_xgboost, test_xgboost, _ = ts_train_test_split(xgboost_response, xgboost_predictors, test_size=0.2)\n",
    "xgboostmodel = xgboost_modelfit(train_xgboost)\n",
    "train_xgboost.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c475c7-d0df-451f-a823-a394f4f30475",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  split the data\n",
    "\n",
    "trainX, trainy = train_xgboost.iloc[:, 1:], train_xgboost['Growth_rate']\n",
    "testX, testy = test_xgboost.iloc[:, 1:], test_xgboost.iloc[:, -0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9951b39d-603a-4f05-b7fa-89acc8d772b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions\n",
    "\n",
    "fitted_growthRate_xgboost = xgboostmodel.predict(trainX)\n",
    "fitted_growthRate_xgboost.squeeze()\n",
    "fitted_growthRate_xgboost = pd.DataFrame(fitted_growthRate_xgboost, columns={'Fitted Ecommerce_GrowthRate'})\n",
    "fitted_growthRate_xgboost.index = train_xgboost.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55004bb-d804-451d-9f77-284713845953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# growth rate prediction\n",
    "\n",
    "fitted_values_xgboost = pd.DataFrame({'GrowthRate': train_xgboost['Growth_rate'],\n",
    "                              'Fitted Value': fitted_growthRate_xgboost.squeeze()})\n",
    "plot_df(fitted_values_xgboost, width=12, height=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c089499d-bbf1-461d-bf4e-deaa2db2abd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_prediction_xgboost(train_xgboost, test_xgboost, dependent_var='Growth_rate'):\n",
    "    \"\"\" Rolling prediction for xgboost\"\"\"\n",
    "    train_samples = train_xgboost.shape[0]\n",
    "    test_samples = test_xgboost.shape[0]\n",
    "    pred_data = pd.DataFrame(columns=None)\n",
    "    test_data = test_xgboost.copy()\n",
    "    for i in range(train_samples+1, train_samples+test_samples+1):\n",
    "        modelfit = xgboost_modelfit(train_xgboost)\n",
    "\n",
    "        # Get first row of test set and make prediction\n",
    "        firstrow_test = np.transpose(pd.DataFrame((test_xgboost.iloc[0, :])))\n",
    "        predicted_val = modelfit.predict(firstrow_test.loc[:, ~firstrow_test.columns.isin([dependent_var])])\n",
    "        predicted_val = pd.DataFrame(predicted_val)\n",
    "        pred_data = pred_data.append(predicted_val)\n",
    "\n",
    "        # update training set with one row\n",
    "        train_xgboost = pd.concat([train_xgboost, firstrow_test])\n",
    "\n",
    "        # Drop first row from test set now\n",
    "        test_xgboost = test_xgboost.drop(f\"{firstrow_test.index[0]}\")\n",
    "\n",
    "    pred_data.index = test_data.index\n",
    "    return pred_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94b1fd5-a9cb-4c67-96b4-aad3ca38efae",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_pred_salesgrowth = rolling_prediction_xgboost(train_xgboost, test_xgboost, dependent_var='Growth_rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0185948-547c-4463-b3c4-867da39b0534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitted and predicted plot of growth rate\n",
    "\n",
    "fitted_values_xgboost = pd.DataFrame({'Ecommerce_GrowthRate': retailEcommercesales_ts['Growth_rate'],\n",
    "                                'Fitted Value': fitted_growthRate_xgboost.squeeze(),\n",
    "                                'Predicted Value': xgboost_pred_salesgrowth.squeeze()})\n",
    "plot_df(fitted_values_xgboost, width=12, height=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c0c1c5-713d-4e9b-8133-9fbda4765cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitted_and_predicted_sales_xgboost(modelfit, pred_EcommerceGrowth, retailEcommercesales, train, test):\n",
    "    base_sales = retailEcommercesales['Ecommerce_sales'][1]\n",
    "\n",
    "    # calculate fitted gdp\n",
    "    X_xgboost = train.loc[:, ~train.columns.isin(['Growth_rate'])]\n",
    "    fitted_values = modelfit.predict(X_xgboost)  # fitted growth rate\n",
    "    fitted_values = pd.DataFrame(fitted_values, columns={'Fitted EcommerceSales_GrowthRate'})\n",
    "    fitted_values.index = train.index\n",
    "\n",
    "    fitted_sales = [0]*(len(fitted_values)+1)\n",
    "    fitted_sales[0] = base_sales\n",
    "    for i, value in enumerate(fitted_values['Fitted EcommerceSales_GrowthRate']):\n",
    "        fitted_sales[i+1] = fitted_sales[i]*(1 + value)\n",
    "    fitted_sales_df = pd.DataFrame(fitted_sales[1:])\n",
    "    fitted_sales_df.index = train.index\n",
    "\n",
    "    base_sales_test = retailEcommercesales[retailEcommercesales.index == train.index[-1]]['Ecommerce_sales'][0]\n",
    "    predicted_sales = [0]*(len(pred_EcommerceGrowth.squeeze()))\n",
    "    actual_sales = base_sales_test\n",
    "    for i, value in enumerate(pred_EcommerceGrowth.squeeze()):\n",
    "        predicted_sales[i] = actual_sales*(1 + value)\n",
    "        actual_sales = retailEcommercesales.loc[test.index[i]][0]\n",
    "    predicted_sales_df = pd.DataFrame(predicted_sales)\n",
    "    predicted_sales_df.index = pred_EcommerceGrowth.index\n",
    "    predicted_sales_df = pd.concat([retailEcommercesales[retailEcommercesales.index == train.index[-1]]['Ecommerce_sales'], predicted_sales_df])\n",
    "\n",
    "    # prediction error calculation\n",
    "    org = retailEcommercesales[retailEcommercesales.index >= predicted_sales_df.index[0]]\n",
    "    error = 0\n",
    "    for i in range(0, predicted_sales_df.shape[0]):\n",
    "        error = error + (org['Ecommerce_sales'][i]-predicted_sales_df[0][i])**2\n",
    "    pred_error = np.sqrt(error/predicted_sales_df.shape[0])\n",
    "    print(f\"Prediction error: {pred_error}\")\n",
    "\n",
    "    # Plot actual and fitted GDP\n",
    "    Actual_sales = retailEcommercesales['Ecommerce_sales'][1:]\n",
    "    fittedandActual_sales = pd.DataFrame({'Actual EcommerceSales': Actual_sales,\n",
    "                                        'Fitted EcommerceSales': fitted_sales_df.squeeze(),\n",
    "                                        'Predicted EcommerceSales': predicted_sales_df.squeeze()\n",
    "                                       })\n",
    "    plot_df(fittedandActual_sales, width=10, height=3)\n",
    "    return pred_error, fittedandActual_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438804c0-0005-443f-afc9-e4a1022f7b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitted and predicted plot\n",
    "\n",
    "plot_sales, actual_sales = fitted_and_predicted_sales_xgboost(xgboostmodel, xgboost_pred_salesgrowth, retailEcommercesales, train_xgboost, test_xgboost)\n",
    "plot_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2012a96-f1e9-41d6-8ae4-e7c4f9d7609b",
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_reg = xgb.XGBRegressor(objective ='reg:linear',learning_rate = 0.01, n_estimators = 500,subsample=0.8, colsample_bytree=0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc90e1b-96d3-45a8-9016-ef315320c6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions\n",
    "xg_reg.fit(trainX,trainy)\n",
    "fitted_growthRate_xgboost = xg_reg.predict(trainX)\n",
    "fitted_growthRate_xgboost.squeeze()\n",
    "fitted_growthRate_xgboost = pd.DataFrame(fitted_growthRate_xgboost, columns={'Fitted Ecommerce_GrowthRate'})\n",
    "fitted_growthRate_xgboost.index = train_xgboost.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c502059f-16c2-46ae-bcea-4f5246ab1d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_pred_salesgrowth = rolling_prediction_xgboost(train_xgboost, test_xgboost, dependent_var='Growth_rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a218fe6-71db-48be-96f3-8872c6e1f9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitted and predicted plot of growth rate\n",
    "\n",
    "fitted_values_xgboost = pd.DataFrame({'Ecommerce_GrowthRate': retailEcommercesales_ts['Growth_rate'],\n",
    "                                'Fitted Value': fitted_growthRate_xgboost.squeeze(),\n",
    "                                'Predicted Value': xgboost_pred_salesgrowth.squeeze()})\n",
    "plot_df(fitted_values_xgboost, width=12, height=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0021e1e1-2ab9-4eb2-b5b0-c744df825bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitted and predicted plot\n",
    "\n",
    "plot_sales, actual_sales = fitted_and_predicted_sales_xgboost(xg_reg, xgboost_pred_salesgrowth, retailEcommercesales, train_xgboost, test_xgboost)\n",
    "plot_sales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba9b79b-3290-442b-8783-1f0f6db7cc00",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75390d7b-44df-45ff-816f-f01d167ac187",
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomForest_modelfit(train_rf, dependent_var='Growth_rate',n_trees=100):\n",
    "    \"\"\" fits Random Forest model to the passed data\"\"\"\n",
    "    x_train, y_train = train_rf.loc[:, ~train_rf.columns.isin([dependent_var])], train_rf[[dependent_var]]\n",
    "    RFmodel = RandomForestRegressor(n_estimators=n_trees)\n",
    "    RFmodel.fit(x_train, y_train)\n",
    "    return RFmodel\n",
    "\n",
    "def rolling_prediction_RF(train, test, dependent_var='Growth_rate',n_trees=100):\n",
    "    \"\"\" Rolling prediction for test set\"\"\"\n",
    "    train_samples = train.shape[0]\n",
    "    test_samples = test.shape[0]\n",
    "    pred_data = pd.DataFrame(columns=None)\n",
    "    test_data = test.copy()\n",
    "    for i in range(train_samples+1, train_samples+test_samples+1):\n",
    "        modelfit = randomForest_modelfit(train, dependent_var,n_trees=100)\n",
    "\n",
    "        # Get first row of test set and make prediction\n",
    "        firstrow_test = np.transpose(pd.DataFrame((test.iloc[0, :])))\n",
    "        predicted_val = modelfit.predict(firstrow_test.loc[:, ~firstrow_test.columns.isin([dependent_var])])\n",
    "        predicted_val = pd.DataFrame(predicted_val)\n",
    "        pred_data = pred_data.append(predicted_val)\n",
    "\n",
    "        # update training set with one row\n",
    "        train = pd.concat([train, firstrow_test])\n",
    "\n",
    "        # Drop first row from test set now\n",
    "        test = test.drop(f\"{firstrow_test.index[0]}\")\n",
    "\n",
    "    pred_data.index = test_data.index\n",
    "    return pred_data\n",
    "\n",
    "# RF Feature Importance Plot\n",
    "def plot_feature_importance(importance, names, model_type, most_important_predictors=20):\n",
    "\n",
    "    #Create arrays from feature importance and feature names\n",
    "    feature_importance = np.array(importance)\n",
    "    feature_names = np.array(names)\n",
    "\n",
    "    #Create a DataFrame using a Dictionary\n",
    "    data={'feature_names':feature_names,'feature_importance':feature_importance}\n",
    "    fi_df = pd.DataFrame(data)\n",
    "\n",
    "    #Sort the DataFrame in order decreasing feature importance\n",
    "    fi_df=fi_df.sort_values(by=['feature_importance'], ascending=False)\n",
    "    fi_df=fi_df[0:most_important_predictors]\n",
    "\n",
    "    #Define size of bar plot\n",
    "    plt.figure(figsize=(10,8))\n",
    "    #Plot Seaborn bar chart\n",
    "    sns.barplot(x=fi_df['feature_importance'], y=fi_df['feature_names'])\n",
    "\n",
    "    #Add chart labels\n",
    "    plt.title(model_type + 'FEATURE IMPORTANCE')\n",
    "    plt.xlabel('FEATURE IMPORTANCE')\n",
    "    plt.ylabel('FEATURE NAMES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb22e4cb-ee23-45a3-a128-35bcd747f0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data for random forest\n",
    "rf_predictors, rf_response = get_lag1_data(retailEcommercesales_ts, detrend_merged_keyword, dependent_var='Growth_rate')\n",
    "\n",
    "print(rf_predictors.shape)\n",
    "print(rf_response.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f791ee-78ac-4c25-b5b4-3fdd94db730a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "train_rf, test_rf, _ = ts_train_test_split(rf_response, rf_predictors, test_size=0.2)\n",
    "train_rf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a2da2f-dea6-4ca7-afc5-84a770b916b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model\n",
    "rfmodel = randomForest_modelfit(train_rf, dependent_var='Growth_rate',n_trees=900)\n",
    "\n",
    "# fitted growth rate\n",
    "X_rf, y_rf = train_rf.loc[:, ~train_rf.columns.isin(['Growth_rate'])], train_rf[['Growth_rate']]\n",
    "fitted_growthRate_rf = rfmodel.predict(X_rf)\n",
    "fitted_growthRate_rf = pd.DataFrame(fitted_growthRate_rf, columns={'Fitted EcommerceSales_GrowthRate'})\n",
    "fitted_growthRate_rf.index = train_rf.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e642a2-4b28-4a80-a042-29c2ac9a4aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rolling prediction of growth rate\n",
    "\n",
    "pred_growthrate_rf = rolling_prediction_RF(train_rf, test_rf, dependent_var='Growth_rate',n_trees=900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5a4f37-abab-4ec5-9fc3-74fb0e4306e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fitted Ecommerce Sales\n",
    "\n",
    "fitted_values_rf = pd.DataFrame({'EcommerceSales_GrowthRate': retailEcommercesales_ts['Growth_rate'],\n",
    "                                'Fitted Value': fitted_growthRate_rf.squeeze(),\n",
    "                                'Predicted Value': pred_growthrate_rf.squeeze()})\n",
    "plot_df(fitted_values_rf, width=12, height=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895b6608-7640-4356-a4dc-aae8f9c5fbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sales, actual_fitted_sales = fitted_and_predicted_sales_xgboost(rfmodel, pred_growthrate_rf, retailEcommercesales, train_rf, test_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20e9df6-813b-4ebc-b6e9-a225fc7267f3",
   "metadata": {},
   "source": [
    "#### GDP keyword file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70909b38-3abd-463d-af30-a2c515ea72ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp_keyword_data = pd.read_csv(\"gdp_keywords_ts.csv\")\n",
    "gdp_keyword_data.rename(columns = {'date':'Date'}, inplace = True)\n",
    "gdp_keyword_data = gdp_keyword_data.set_index(['Date'])\n",
    "gdp_keyword_data.index = pd.to_datetime(gdp_keyword_data.index) \n",
    "gdp_keyword_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801f664b-f028-4bd9-86be-018aaa07ee4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation check\n",
    "cols = list()\n",
    "data = pd.merge(retailEcommercesales, gdp_keyword_data, left_index=True, right_index=True)\n",
    "\n",
    "for i in range(0, data.iloc[:,2:].shape[1]):\n",
    "    corr, _ = pearsonr(data['Ecommerce_sales'], data.iloc[:, i+2])\n",
    "    if abs(corr) > 0.4:\n",
    "        cols.append(data.columns[i+2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8120dec6-962d-4225-a727-d8b3eb292eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81cc7f0-d318-4b41-97a2-90df4136d823",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_model_rf(kfolds=5,train_set=train_rf,dependent_var='Growth_rate',n_trees =100):\n",
    "    entry_count = int(train_set.shape[0]/kfolds)\n",
    "    train = train_set.iloc[:entry_count,:]\n",
    "    error = 0\n",
    "\n",
    "    for i in range(entry_count,len(train_set),entry_count):\n",
    "        test = train_set.iloc[i:i+entry_count,:]\n",
    "        #rfmodel_temp = modeltype(train, dependent_var)\n",
    "        pred_growthrate_rf_temp = rolling_prediction_RF(train, test,dependent_var,n_trees)\n",
    "        pred_growthrate_rf_temp = pred_growthrate_rf_temp.rename(columns = {0:dependent_var})\n",
    "        #train_df = pd.merge(test_new,pred_growthrate_rf_temp,left_index=True, right_index = True)\n",
    "        train = train.append(test)\n",
    "        error = error + np.sqrt(np.mean(pow(pred_growthrate_rf_temp[dependent_var] - test[dependent_var],2)))\n",
    "    return error/(kfolds-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22551017-c11f-4bda-981c-432a956298a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross validation for trees between 100 and 1000 in RF\n",
    "\n",
    "kfolds = 5\n",
    "min_trees = 100\n",
    "max_trees = 1000\n",
    "step_size = 100\n",
    "rf_cv_df = pd.DataFrame(columns=[\"Num of trees\", \"Cross validation error\"])\n",
    "for i, num_trees in enumerate(range(min_trees, max_trees+1, step_size)):\n",
    "    error = cv_model_rf(kfolds, train_rf, 'Growth_rate', n_trees=num_trees)\n",
    "    rf_cv_df.loc[i, \"Num of trees\"] = num_trees\n",
    "    rf_cv_df.loc[i, \"Cross validation error\"] = error\n",
    "\n",
    "print(rf_cv_df[rf_cv_df['Cross validation error'] == rf_cv_df['Cross validation error'].min()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d660cc2-32ee-4921-947d-4d792cc6baf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "aa4700f7-82ff-48d2-a3d9-b89378c4d2e2",
   "metadata": {},
   "source": [
    "def cv_model_xgboost(kfolds=5,train_set=train_xgboost,dependent_var='Growth_rate',n_trees =500):\n",
    "    entry_count = int(train_set.shape[0]/kfolds)\n",
    "    train = train_set.iloc[:entry_count,:]\n",
    "    error = 0\n",
    "\n",
    "    for i in range(entry_count,len(train_set),entry_count):\n",
    "        test = train_set.iloc[i:i+entry_count,:]\n",
    "        #rfmodel_temp = modeltype(train, dependent_var)\n",
    "        pred_growthrate_rf_temp = rolling_prediction_xgboost(train, test,dependent_var,n_trees)\n",
    "        pred_growthrate_rf_temp = pred_growthrate_rf_temp.rename(columns = {0:dependent_var})\n",
    "        #train_df = pd.merge(test_new,pred_growthrate_rf_temp,left_index=True, right_index = True)\n",
    "        train = train.append(test)\n",
    "        error = error + np.sqrt(np.mean(pow(pred_growthrate_rf_temp[dependent_var] - test[dependent_var],2)))\n",
    "    return error/(kfolds-1)\n",
    "\n",
    "xg_reg = xgb.XGBRegressor(objective ='reg:linear',learning_rate = 0.01, n_estimators = 500,subsample=0.8, colsample_bytree=0.85)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
