{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fcfce433-53a7-4ef3-aff4-74d7233f88e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import time\n",
    "\n",
    "from statistics import mean, stdev\n",
    "from pytrends.request import TrendReq\n",
    "from urllib3.exceptions import MaxRetryError\n",
    "\n",
    "from statsmodels.tsa.stattools import adfuller, kpss\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "\n",
    "# our modules\n",
    "from plotSeries import *\n",
    "from checkStationarity import *\n",
    "from GoogleTrendsData import *\n",
    "from makeSeriesStationary import *\n",
    "from predictorsSelection import *\n",
    "from dataPreProcessing import *\n",
    "from tsModels import *\n",
    "from rollingPredictionfuns import *\n",
    "from fittedAndPredictedValuefuns import *\n",
    "from bootstrapfuns import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6018e9b-f8c4-4474-b473-559e8807cfac",
   "metadata": {},
   "source": [
    "# 1. Read data (StatCan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aadd1bd8-23f1-4255-8b55-04dd74753433",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../data/retailEcommercesales/retailEcommerceSales.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Reading file\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../../data/retailEcommercesales/retailEcommerceSales.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# data filter\u001b[39;00m\n\u001b[0;32m      5\u001b[0m retailEcommercesales \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;241m~\u001b[39mdata[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSales\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mcontains(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124munadjusted\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:586\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    571\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    572\u001b[0m     dialect,\n\u001b[0;32m    573\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    582\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    583\u001b[0m )\n\u001b[0;32m    584\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 586\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:482\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    479\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    481\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 482\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    484\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    485\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:811\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwds:\n\u001b[0;32m    809\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m--> 811\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1040\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1036\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1037\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown engine: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mengine\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (valid options are \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmapping\u001b[38;5;241m.\u001b[39mkeys()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1038\u001b[0m     )\n\u001b[0;32m   1039\u001b[0m \u001b[38;5;66;03m# error: Too many arguments for \"ParserBase\"\u001b[39;00m\n\u001b[1;32m-> 1040\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m mapping[engine](\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions)\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:51\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     48\u001b[0m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musecols\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39musecols\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# open handles\u001b[39;00m\n\u001b[1;32m---> 51\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open_handles\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# Have to pass int, would break tests using TextReader directly otherwise :(\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\pandas\\io\\parsers\\base_parser.py:222\u001b[0m, in \u001b[0;36mParserBase._open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_handles\u001b[39m(\u001b[38;5;28mself\u001b[39m, src: FilePathOrBuffer, kwds: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    220\u001b[0m \u001b[38;5;124;03m    Let the readers open IOHandles after they are done with their potential raises.\u001b[39;00m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 222\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    223\u001b[0m \u001b[43m        \u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    224\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    226\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    227\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    228\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    229\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    230\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\pandas\\io\\common.py:702\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    697\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    698\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    701\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 702\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    703\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    704\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    705\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    706\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    707\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    708\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    709\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    710\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    711\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../data/retailEcommercesales/retailEcommerceSales.csv'"
     ]
    }
   ],
   "source": [
    "# Reading file\n",
    "data = pd.read_csv('../../data/retailEcommercesales/retailEcommerceSales.csv',sep=',')\n",
    "\n",
    "# data filter\n",
    "retailEcommercesales = data[~data[\"Sales\"].str.contains('unadjusted')]\n",
    "retailEcommercesales = retailEcommercesales.filter(['REF_DATE','VALUE'])\n",
    "\n",
    "# rename columns\n",
    "retailEcommercesales = retailEcommercesales.rename(columns = {'REF_DATE': 'Date', 'VALUE': 'Ecommerce_sales'})\n",
    "retailEcommercesales_ts = retailEcommercesales.copy()\n",
    "\n",
    "#Changing data type of date\n",
    "retailEcommercesales=retailEcommercesales.set_index(['Date'])\n",
    "retailEcommercesales.index = pd.to_datetime(retailEcommercesales.index)\n",
    "retailEcommercesales_ts = retailEcommercesales_ts.set_index('Date')\n",
    "retailEcommercesales_ts.index = pd.to_datetime(retailEcommercesales_ts.index)\n",
    "\n",
    "# calculate and add growth rate to the dataframe\n",
    "retailEcommercesales_ts['Growth_rate'] = retailEcommercesales_ts.pct_change()\n",
    "retailEcommercesales_ts = retailEcommercesales_ts.dropna() # removing NA\n",
    "\n",
    "# check sttaionarity of time series\n",
    "check_stationarity(retailEcommercesales_ts[['Growth_rate']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896542e8-fa1a-4939-885b-5c5bd18fca2f",
   "metadata": {},
   "source": [
    "# 2. Get Google Trends data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6de2275a-dc15-42cf-a26c-d6561954d697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading keywords\n",
    "keywords_csv = pd.read_csv('../../data/keywords_data/EECOMMERCE.csv')\n",
    "\n",
    "# extracting timeseries dataframe\n",
    "for index, row in keywords_csv.iterrows():\n",
    "    #calling Pytrends\n",
    "    data, queries, topics=ecommerce_trend(keywords=[str(row['Keyword'])],category=str(row['SubcatNo']))\n",
    "    \n",
    "    if index==0:\n",
    "        FinalData, queries, topics=ecommerce_trend(keywords=[str(row['Keyword'])],category=str(row['SubcatNo']))\n",
    "        FinalData.rename(columns = {'':str(row['Keyword'])}, inplace = True)    #column name for frame\n",
    "        FinalData=FinalData.drop(columns=['isPartial'])   #remove column\n",
    "    else:\n",
    "        data, queries, topics=ecommerce_trend(keywords=[str(row['Keyword'])],category=str(row['SubcatNo']))\n",
    "        data.rename(columns = {'':str(row['Keyword'])}, inplace = True)\n",
    "        data=data.drop(columns=['isPartial'])\n",
    "        data = data[str(row['Keyword'])]\n",
    "        FinalData = FinalData.join(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e905c1e-9468-49f4-9fa8-3c60ca157354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write data to csv\n",
    "FinalData.to_csv('EcommerceKeywordTimeSeries.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96c92665-b098-47ed-876c-77f879247721",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pre-processing time series\n",
    "ecommerce_keyword_ts = pd.read_csv('EcommerceKeywordTimeSeries.csv')\n",
    "ecommerce_keyword_ts.rename(columns = {'date':'Date'}, inplace = True)\n",
    "ecommerce_keyword_ts = ecommerce_keyword_ts.set_index(['Date'])\n",
    "ecommerce_keyword_ts.index = pd.to_datetime(ecommerce_keyword_ts.index)\n",
    "ecommerce_keyword_ts = ecommerce_keyword_ts.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47699ac-23e4-44a2-b0b1-d14ac0be3de5",
   "metadata": {},
   "source": [
    "# 3. Make data stationary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11f3435c-f021-43ce-bbab-23468d0b368a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series DoorDash is trend stationary, trend needs to be removed\n",
      "Series square online is not stationary, differencing can be used to make it stationary\n",
      "All other series are stationary\n"
     ]
    }
   ],
   "source": [
    "#extracting and removing trend\n",
    "normalized_ecommerce_keyword = normalize(ecommerce_keyword_ts)\n",
    "detrend_ecommerce_keyword = (detrend(normalized_ecommerce_keyword))\n",
    "check_stationarity(detrend_ecommerce_keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a7b4bfb-2fb8-4378-a34f-7c67b8685331",
   "metadata": {},
   "outputs": [],
   "source": [
    "# response and predictors structing\n",
    "predictor = make_predictors_df(detrend_ecommerce_keyword)\n",
    "response = make_predictors_df(retailEcommercesales_ts[['Growth_rate']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820e6fc6-abe9-4631-8261-5d8d38a6c035",
   "metadata": {},
   "source": [
    "# 4. Model fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d418d249-dcc8-4c65-8733-247e061b06e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction error: 365396.9182999891\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "365396.9182999891"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest\n",
    "\n",
    "rf_predictors, rf_response = get_lag1_data_ecommerce(retailEcommercesales_ts, detrend_ecommerce_keyword, response_var='Growth_rate')\n",
    "\n",
    "#Splitting data in training and testing\n",
    "train_rf, test_rf, extra_rf = ts_train_test_split(rf_response, rf_predictors, test_size=0.2)\n",
    "\n",
    "#Fitting RF model\n",
    "rfmodel = randomForest_modelfit(train_rf, response_var='Growth_rate', n_trees=600)\n",
    "x_rf, y_rf = train_rf.loc[:, ~train_rf.columns.isin(['Growth_rate'])], train_rf[['Growth_rate']]\n",
    "\n",
    "# fitted growth rate\n",
    "fitted_growthRate_rf = rfmodel.predict(x_rf)\n",
    "fitted_growthRate_rf = pd.DataFrame(fitted_growthRate_rf, columns={'Fitted GrowthRate'})\n",
    "fitted_growthRate_rf.index = train_rf.index\n",
    "\n",
    "#Random Forest Predictions\n",
    "rf_pred_ecommercegrowth = rolling_prediction_randomForest(train_rf, test_rf, extra_rf,dependent_var='Growth_rate',\n",
    "                                              n_trees=600)\n",
    "\n",
    "#rf_pred_retailgrowth\n",
    "\n",
    "# Fitted and predicted retail sales value\n",
    "pred_error, fig, data = fitted_and_predicted_sales_ecommerce(rfmodel, \n",
    "                                                    rf_pred_ecommercegrowth, \n",
    "                                                    retailEcommercesales, train_rf, test_rf, extra_rf)\n",
    "pred_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb6ee255-1f67-44f3-8bf9-29056cb3360a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bootstrap for GDP\n",
    "\n",
    "# create bootstrap samples\n",
    "bs_samples = get_bootstrap_samples(train_rf, n_sample=100, rs=None)  # rs = RandomState(1234)\n",
    "\n",
    "# get predicted growth rate uisng bootstrap samples\n",
    "# predicted_growth_df = pd.DataFrame(columns=list(range(0, len(bs_samples))))\n",
    "# for i, df in enumerate(bs_samples):\n",
    "#     predicted_growth_temp = rolling_prediction_randomForest(df, test_rf, extra_rf, dependent_var='Growth_rate',n_trees=100)\n",
    "#     predicted_growth_df.iloc[:, i] = predicted_growth_temp[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9c3754-42f3-4b45-94a5-820b5af99a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs_samples"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
